Target capture data: Reads processing, quality control and variant
calling
================

Trim adapters:

``` bash
in_dir=./turqueti/tarcap/raw
out_dir=./turqueti/tarcap/cleaned_processshortreads

/sw/containers/stacks-2.60.sif stacks process_shortreads -P -p $in_path -o $out_dir --adapter_1 AGATCGGAAGAGC --adapter_2 AGATCGGAAGAGC --adapter_mm 0
```

Discard reads with phred quality (Q) less than 20, trim polyG (problem
with early Novaseq):

``` bash
for sample in `ls ./turqueti/tarcap/cleaned_processshortreads/*.1.fq.gz`
do

in_dir=./turqueti/tarcap/cleaned_processshortreads
out_dir=./turqueti/tarcap/cleaned_fastp
base=$(basename $sample ".1.fq.gz")

/sw/containers/fastp-0.20.1.sif fastp -i ${in_dir}/${base}.1.fq.gz -I ${in_dir}/${base}.2.fq.gz  -o ${out_dir}/${base}.1.fq.gz -O ${out_dir}/${base}.2.fq.gz -q 20 --trim_poly_g

done
```

Truncate final read length to a uniform length of 140 bp:

``` bash
for sample in `ls ./turqueti/tarcap/cleaned_fastp/*.1.fq.gz`
do

in_dir=./turqueti/tarcap/cleaned_fastp
out_dir=./turqueti/tarcap/cleaned_final
base=$(basename $sample ".1.fq.gz")

/sw/containers/fastp-0.20.1.sif fastp -i ${in_dir}/${base}.1.fq.gz -I ${in_dir}/${base}.2.fq.gz  -o ${out_dir}/${base}.1.fq.gz -O ${out_dir}/${base}.2.fq.gz -l 140 --max_len1 140 --max_len2 140 -A -G -Q 

done
```

Finally, check cleaned reads quality using fastqc:

``` bash
/sw/containers/fastqc-0.11.9.sif fastqc -o ./turqueti/tarcap/cleaned_final/fastqc ./turqueti/tarcap/cleaned_final/$sample.1.fq.gz ./cleaned_final/$sample.2.fq.gz
```

Screen for contaminants using kraken:

``` bash
samples="JR179_403
JR179_674
etc"

i=1
for sample in $samples
do
   /sw/containers/kraken-1.1.1.sif kraken --threads 12 --db $databse --fastq-input --paired ./cleaned_final/${sample}.1.fq.gz ./turqueti/tarcap/cleaned_final/${sample}.2.fq.gz --gzip-compressed > ./turqueti/tarcap/cleaned_final/kraken/${sample}_initial.txt
   let "i+=1";
done
```

Map cleaned reads to consensus loci (fasta file used to generate target
capture baits):

``` bash
REF=./turqueti/tarcap/reference/unique_consensus_loci.fa

INDS=($(for i in ./turqueti/tarcap/cleaned_final/*.1.fq.gz; do echo $(basename ${i%.1*}); done))

for IND in ${INDS[@]};
do
    # declare variables
    FORWARD=./turqueti/tarcap/cleaned_final/${IND}.1.fq.gz
    REVERSE=./turqueti/tarcap/cleaned_final/${IND}.2.fq.gz
    OUTPUT=./turqueti/tarcap/bwa_sorted_bam/${IND}_sort.bam

    # then align and sort
    echo "Aligning $IND with bwa"
    /sw/containers/bwa-0.7.17.sif bwa mem -M -t 15 $REF $FORWARD $REVERSE |
    /sw/containers/samtools-1.13.sif samtools view -b -@ 15 | \
    /sw/containers/samtools-1.13.sif samtools sort -@ 15 -T ${IND} > $OUTPUT
done
```

Run samtools flagstat for some sanity check:

``` bash
/sw/containers/samtools-1.13.sif samtools flagstat ${sample}_sort.bam
```

Remove PCR duplicates using Picard:

``` bash
module load java

for sample in `ls ./turqueti/tarcap/bwa_sorted_bam/*_sort.bam`
do
base=$(basename $sample "_sort.bam")

/sw/containers/picard-2.26.6.sif java -jar /usr/share/java/picard.jar MarkDuplicates \
      I=./turqueti/tarcap/bwa_sorted_bam/${base}_sort.bam \
      O=./turqueti/tarcap/bwa_sorted_bam_pcrrm/${base}.rmd.bam \
      REMOVE_DUPLICATES=true \
      ASSUME_SORTED=true VALIDATION_STRINGENCY=SILENT \
      MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=1000 \
      M=./turqueti/tarcap/bwa_sorted_bam_pcrrm/marked_dup_metrics.txt
done
```

Rename bam file names and index bam files:

``` bash
cd ./turqueti/tarcap/bwa_sorted_bam_pcrrm

# rename
for file in *.rmd.bam
do
  mv "$file" "${file%.rmd.bam}.bam"
done

# index
samples="JR179_403
JR179_674
etc"

i=1
for sample in $samples
do
   /sw/containers/samtools-1.13.sif samtools index ./${sample}.bam
   let "i+=1";
done
```

Call SNPs across samples using bcftools (inlcuding both monomorphic and
polymorphic sites):

``` bash
REF=./turqueti/tarcap/reference/unique_consensus_loci.fa

cd ./turqueti/tarcap/bwa_sorted_bam_pcrrm

/sw/containers/bcftools-1.13.sif bcftools mpileup -a AD,DP,SP -Ou --threads 10 -f $REF \
CT931.bam 44064_1.bam 44117.bam ... PT117AP.bam | \
/sw/containers/bcftools-1.13.sif bcftools call -a GQ,GP -m -Oz -o ./turqueti/tarcap/bcftools_mpileup/raw.vcf.gz --threads 10
```

Check if we we have in the raw.vcf.gz:

``` bash
# missingness per site
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --missing-site --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# missingness per individual
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --missing-indv --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# allele frequency
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --freq2 --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# mean depth per individual
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --depth --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# mean depth per site
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --site-mean-depth --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# site quality
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --site-quality --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
# heterozygosity per individual
/sw/containers/vcftools-0.1.16.sif vcftools --gzvcf raw.vcf.gz --het --out ./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat --max-alleles 2
```

Visualise the variant calling statistics in raw.vcf.gz:

``` r
library(tidyverse)
library(ggplot2)

setwd("./turqueti/tarcap/bcftools_mpileup/raw_vcf_stat")

# Check variant quality (Phred encoded)
var_qual <- read_delim("./raw_vcf_stat.lqual", delim = "\t",
                       col_names = c("chr", "pos", "qual"), skip = 1)
a <- ggplot(var_qual, aes(qual)) + geom_density(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light()

# Variant mean depth
var_depth <- read_delim("./raw_vcf_stat.ldepth.mean", delim = "\t",
                        col_names = c("chr", "pos", "mean_depth", "var_depth"), skip = 1)

a <- ggplot(var_depth, aes(mean_depth)) + geom_density(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light() + xlim(0, 100) 

summary(var_depth$mean_depth)

# Variant missingness
var_miss <- read_delim("./raw_vcf_stat.lmiss", delim = "\t",
                       col_names = c("chr", "pos", "nchr", "nfiltered", "nmiss", "fmiss"), skip = 1)
a <- ggplot(var_miss, aes(fmiss)) + geom_density(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light() 

summary(var_miss$fmiss)

# Minor allele frequency
var_freq <- read_delim("./raw_vcf_stat.frq", delim = "\t",
                       col_names = c("chr", "pos", "nalleles", "nchr", "a1", "a2"), skip = 1)
## find minor allele frequency
var_freq$maf <- var_freq %>% select(a1, a2) %>% apply(1, function(z) min(z))
a <- ggplot(var_freq, aes(maf)) + geom_density(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light() 

summary(var_freq$maf)

# Mean depth per individual
ind_depth <- read_delim("./raw_vcf_stat.idepth", delim = "\t",
                        col_names = c("ind", "nsites", "depth"), skip = 1)
a <- ggplot(ind_depth, aes(depth)) + geom_histogram(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light()

summary(ind_depth$depth)

# Proportion of missing data per individual
ind_miss  <- read_delim("./raw_vcf_stat.imiss", delim = "\t",
                        col_names = c("ind", "ndata", "nfiltered", "nmiss", "fmiss"), skip = 1)
a <- ggplot(ind_miss, aes(fmiss)) + geom_histogram(fill = "dodgerblue1", colour = "black", alpha = 0.3)
a + theme_light()
```
